{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import gc\n",
    "import optuna\n",
    "from datetime import datetime, timezone\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import joblib as jl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "today = datetime.now(timezone.utc).strftime(\"%Y_%m_%d\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# helpers\n",
    "sys.path.append(\"..\")\n",
    "from helpers.loss_functions import *\n",
    "from helpers.mlflow import *\n",
    "\n",
    "# data\n",
    "train_path = \"../data/mushrooms/train.csv\"\n",
    "test_path = \"../data/mushrooms/test.csv\"\n",
    "cache_path = \"../data/mushrooms/cache\"\n",
    "# model\n",
    "is_tunning = True\n",
    "try:\n",
    "    rs = subprocess.check_output(\"nvidia-smi\")\n",
    "    device = \"cuda\" if rs is not None else \"cpu\"\n",
    "    print(f\"device: {device}\")\n",
    "except (\n",
    "    Exception\n",
    "):  # this command not being found can raise quite a few different errors depending on the configuration\n",
    "    print(\"No Nvidia GPU in system!\")\n",
    "    device = \"cpu\"\n",
    "goal = \"binary:logistic\"\n",
    "\n",
    "# custom metric\n",
    "objective_dict = {\n",
    "    \"binary:logistic\": {\n",
    "        \"metric\": {\n",
    "            \"is_custom\": True,\n",
    "            \"name\": \"MCC\",\n",
    "            \"fval\": mcc_metric_v2,\n",
    "        },\n",
    "        \"direction\": \"maximize\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# objective_dict = {\n",
    "#     \"binary:logistic\": {\n",
    "#         \"metric\": {\n",
    "#             \"is_custom\": False,\n",
    "#             \"name\": \"logloss\",\n",
    "#             \"fval\": None,\n",
    "#         },\n",
    "#         \"direction\": \"minimize\",\n",
    "#     }\n",
    "# }\n",
    "metric = objective_dict[goal][\"metric\"][\"name\"]\n",
    "is_custom_metric = objective_dict[goal][\"metric\"][\"is_custom\"]\n",
    "fval = objective_dict[goal][\"metric\"][\"fval\"]\n",
    "direction = objective_dict[goal][\"direction\"]\n",
    "best_params = {\n",
    "    \"device\": device,\n",
    "    \"verbosity\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "print(f\"train size: {train.shape}\")\n",
    "test = pd.read_csv(test_path)\n",
    "print(f\"test size: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"class\"\n",
    "\n",
    "categorical_cols = (\n",
    "    train.drop(columns=target).select_dtypes(include=\"object\").columns.to_list()\n",
    ")\n",
    "for c in categorical_cols:\n",
    "    train[c] = train[c].astype(\"category\")\n",
    "    test[c] = test[c].astype(\"category\")\n",
    "numerical_cols = (\n",
    "    train.drop(columns=\"id\").select_dtypes(include=\"number\").columns.to_list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.drop(columns=target),\n",
    "    train[target],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train[target],\n",
    ")\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create the numerical and categorical pipelines\n",
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        # (\"minmax\", MinMaxScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the full pipeline with the XGBoost model\n",
    "data_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "# Binarize the target labels\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_binarized = lb.fit_transform(y_train)\n",
    "y_val_binarized = lb.transform(y_val)\n",
    "\n",
    "# prepare data for training\n",
    "dtrain = xgb.DMatrix(X_train_transformed, label=y_train_binarized)\n",
    "dval = xgb.DMatrix(X_val_transformed, label=y_val_binarized)\n",
    "dtest = xgb.DMatrix(X_test_transformed)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "maximize = direction == \"maximize\"\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    hyper_parameters = {\n",
    "        **best_params,\n",
    "        **{\n",
    "            \"objective\": goal,\n",
    "            \"tree_method\": \"gpu_hist\",\n",
    "            \"eta\": trial.suggest_float(\"eta\", 0.001, 0.1),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.001, 0.1),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.001, 0.2),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.001, 0.1),\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 0.001, 0.1),\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 0.001, 0.1),\n",
    "        },\n",
    "    }\n",
    "    # evals_result = {}\n",
    "    # print(f\"maximize: {maximize}\")\n",
    "    # if is_custom_metric:\n",
    "    #     model = xgb.train(\n",
    "    #         params=hyper_parameters,\n",
    "    #         dtrain=dtrain,\n",
    "    #         maximize=maximize,\n",
    "    #         num_boost_round=4000,\n",
    "    #         evals=[(dval, \"eval\")],\n",
    "    #         feval=fval,\n",
    "    #         evals_result=evals_result,\n",
    "    #         early_stopping_rounds=100,\n",
    "    #     )\n",
    "    # else:\n",
    "    #     model = xgb.train(\n",
    "    #         params=hyper_parameters,\n",
    "    #         dtrain=dtrain,\n",
    "    #         maximize=maximize,\n",
    "    #         num_boost_round=4000,\n",
    "    #         evals=[(dval, \"eval\")],\n",
    "    #         evals_result=evals_result,\n",
    "    #         early_stopping_rounds=200,\n",
    "    #     )\n",
    "\n",
    "    # KFold cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_results = xgb.cv(\n",
    "        hyper_parameters,\n",
    "        dtrain,\n",
    "        num_boost_round=1000,\n",
    "        folds=kf,\n",
    "        early_stopping_rounds=50,\n",
    "        feval=fval,  # Custom evaluation metric\n",
    "        maximize=True,\n",
    "        as_pandas=True,\n",
    "        seed=42,\n",
    "        show_stdv=True,\n",
    "        verbose_eval=True,\n",
    "    )\n",
    "    # evals_result[\"eval\"][metric][-1]\n",
    "    # Use the best score for the final iteration\n",
    "    best_score = cv_results[\"test-MCC-mean\"].max()\n",
    "    gc.collect()\n",
    "    return best_score\n",
    "\n",
    "\n",
    "if is_tunning:\n",
    "    # Create or load a study\n",
    "    today = datetime.now(timezone.utc).strftime(\"%Y_%m_%d\")\n",
    "    curr_timestamp = int(datetime.now(timezone.utc).timestamp())\n",
    "    study_name = f\"study_{today}_{curr_timestamp}\"\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=f\"sqlite:///{study_name}.db\",\n",
    "        direction=direction,\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=None, show_progress_bar=True)\n",
    "    # Print best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(\"Best trial:\")\n",
    "    print(f\" {metric}:\", best_trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    study_best_params = study.best_params\n",
    "    best_params.update(study_best_params)\n",
    "    jl.dump(best_params, \"best_params.pkl\")\n",
    "    # 0.03734 anh Tu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mlflow\n",
    "mlflow.xgboost.autolog()\n",
    "model_name = \"poisonous-mushroom-classifier\"\n",
    "project_name = \"Binary Prediction of Poisonous Mushrooms\"\n",
    "exp_name = \"train-mushroom-classifier\"\n",
    "exp_desc = \"Training model to submit to Binary Prediction of Poisonous Mushrooms.\"\n",
    "mlf_client = Mlflow(model_name=model_name)\n",
    "mlf_client.get_or_create_exp(\n",
    "    project_name=project_name,\n",
    "    experiment_name=exp_name,\n",
    "    experiment_description=exp_desc,\n",
    ")\n",
    "curr_timestamp = int(datetime.now(timezone.utc).timestamp())\n",
    "\n",
    "artifact_path = \"model\"\n",
    "with mlflow.start_run(\n",
    "    run_name=f\"mean_strategy_{curr_timestamp}\",\n",
    "    tags={\"metric\": \"logloss\"},\n",
    "    description=None,\n",
    "    log_system_metrics=True,\n",
    ") as run:\n",
    "    try:\n",
    "        mlflow.log_artifact(local_path=f\"{study_name}.db\", artifact_path=artifact_path)\n",
    "    except:\n",
    "        pass\n",
    "    # Use tunned params\n",
    "    # tunned_params = {\n",
    "    #     \"eta\": 0.1899871885683955,\n",
    "    #     \"max_depth\": 10,\n",
    "    #     \"min_child_weight\": 2,\n",
    "    #     \"gamma\": 0.42570860420610934,\n",
    "    #     \"subsample\": 0.74464089552046,\n",
    "    #     \"colsample_bytree\": 0.6449797444444113,\n",
    "    #     \"lambda\": 0.4134501484785982,\n",
    "    #     \"alpha\": 6.520908679019516,\n",
    "    # }\n",
    "\n",
    "    # best so far\n",
    "    # {\n",
    "    #     \"eta\": 0.018087779785882732,\n",
    "    #     \"max_depth\": 10,\n",
    "    #     \"min_child_weight\": 2,\n",
    "    #     \"gamma\": 0.42570860420610934,\n",
    "    #     \"subsample\": 0.74464089552046,\n",
    "    #     \"colsample_bytree\": 0.6449797444444113,\n",
    "    #     \"lambda\": 0.4134501484785982,\n",
    "    #     \"alpha\": 6.520908679019516,\n",
    "    # }\n",
    "\n",
    "    # best_params.update(tunned_params)\n",
    "    print(f\"best_params: {best_params}\")\n",
    "    print(\"Training best model...\")\n",
    "    evals_best_result = {}\n",
    "    # Create the full pipeline with the XGBoost model\n",
    "    if is_custom_metric:\n",
    "        print(\"Training with custom metric\")\n",
    "        model = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=5000,\n",
    "            evals=[(dval, \"eval\")],\n",
    "            feval=fval,\n",
    "            maximize=maximize,\n",
    "            evals_result=evals_best_result,\n",
    "            early_stopping_rounds=100,\n",
    "        )\n",
    "    else:\n",
    "        print(\"Training with original metric\")\n",
    "        model = xgb.train(\n",
    "            params=best_params,\n",
    "            dtrain=dtrain,\n",
    "            maximize=maximize,\n",
    "            num_boost_round=5000,\n",
    "            evals=[(dval, \"eval\")],\n",
    "            evals_result=evals_best_result,\n",
    "            early_stopping_rounds=400,\n",
    "        )\n",
    "\n",
    "    mcc, _, validate_df = matthews_corrcoef_score(model, dval, y_val_binarized, lb)\n",
    "    # logs evaluation tables\n",
    "    mlflow.log_table(data=validate_df, artifact_file=f\"eval_results_{today}.json\")\n",
    "\n",
    "    # logs metrics\n",
    "    metrics = {}\n",
    "    metrics[\"MCC\"] = mcc\n",
    "    metrics[\"logloss\"] = evals_best_result[\"eval\"][\"logloss\"][-1]\n",
    "    mlflow.log_metrics(metrics)\n",
    "    _, classes, _ = matthews_corrcoef_score(model, dtest, None, lb)\n",
    "    signature = infer_signature(X_test_transformed, classes)\n",
    "    mlflow.xgboost.log_model(\n",
    "        xgb_model=model,\n",
    "        artifact_path=artifact_path,\n",
    "        signature=signature,\n",
    "    )\n",
    "    # Register model name in the model registry\n",
    "    try:\n",
    "        mlf_client.register_model()\n",
    "    except:\n",
    "        print(f\"model {model_name} already registered\")\n",
    "    # Model versioning\n",
    "    mv = mlf_client.version_model(run.info.run_id)\n",
    "    print(f\"Name: {mv.name}\")\n",
    "    print(f\"Version: {mv.version}\")\n",
    "    print(f\"Description: {mv.description}\")\n",
    "    print(f\"Status: {mv.status}\")\n",
    "    print(f\"Stage: {mv.current_stage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(X_test_transformed)\n",
    "_, classes, _ = matthews_corrcoef_score(model, dtest, None, lb)\n",
    "\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = test[\"id\"]\n",
    "submit_df[\"class\"] = classes\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "feature_important = model.get_score(importance_type=\"gain\")\n",
    "keys = list(feature_important.keys())\n",
    "values = list(feature_important.values())\n",
    "\n",
    "data = pd.DataFrame(data=values, index=keys, columns=[\"score\"]).sort_values(\n",
    "    by=\"score\", ascending=False\n",
    ")\n",
    "data.nlargest(40, columns=\"score\").plot(\n",
    "    kind=\"barh\", figsize=(20, 10)\n",
    ")  ## plot top 40 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
