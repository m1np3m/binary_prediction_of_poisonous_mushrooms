{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "import joblib as jl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    OrdinalEncoder,\n",
    "    LabelBinarizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "train_path = \"/home/manpm/Developers/kaggle/data/mushrooms/train.csv\"\n",
    "test_path = \"/home/manpm/Developers/kaggle/data/mushrooms/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (3116945, 22)\n",
      "test size: (2077964, 21)\n",
      "Preprocessing...\n",
      "Exporting to pickple...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "train = pd.read_csv(train_path)\n",
    "print(f\"train size: {train.shape}\")\n",
    "X_test = pd.read_csv(test_path)\n",
    "print(f\"test size: {X_test.shape}\")\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = X_test[\"id\"]\n",
    "y_train = train[\"class\"]\n",
    "X_train = train.drop(columns=[\"id\", \"class\"], axis=1)\n",
    "X_test.drop(columns=[\"id\"], inplace=True, axis=1)\n",
    "\n",
    "# prepare columns\n",
    "target = \"class\"\n",
    "\n",
    "categorical_cols = (\n",
    "    train.drop(columns=target).select_dtypes(include=\"object\").columns.to_list()\n",
    ")\n",
    "\n",
    "numerical_cols = (\n",
    "    train.drop(columns=\"id\").select_dtypes(include=\"number\").columns.to_list()\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "# get top 10 most frequent names\n",
    "n = 15\n",
    "for c in categorical_cols:\n",
    "    train_mode_values = X_train[c].value_counts()[:n].index.tolist()\n",
    "    X_train.loc[~X_train[c].isin(train_mode_values), c] = \"other\"\n",
    "    test_mode_values = X_test[c].value_counts()[:n].index.tolist()\n",
    "    X_test.loc[~X_test[c].isin(test_mode_values), c] = \"other\"\n",
    "\n",
    "\n",
    "# Create the numerical and categorical pipelines\n",
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # (\"minmax\", MinMaxScaler()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the full pipeline with the XGBoost model\n",
    "data_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "    ]\n",
    ")\n",
    "# Preprocess the data\n",
    "X_all = pd.concat([X_train, X_test])\n",
    "data_pipeline.fit(X_all)\n",
    "del X_all\n",
    "gc.collect()\n",
    "# data_pipeline.set_output(transform=\"polars\")\n",
    "# X = pl.from_pandas(X_all)\n",
    "# data_pipeline.fit(X)\n",
    "X_test_transformed = data_pipeline.transform(X_test)\n",
    "X_train_transformed = data_pipeline.transform(X_train)\n",
    "\n",
    "# Binarize the target labels\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_binarized = lb.fit_transform(y_train)\n",
    "\n",
    "print(f\"Exporting to pickple...\")\n",
    "jl.dump(X_train_transformed, \"X_train.pkl\")\n",
    "jl.dump(y_train_binarized, \"y_train.pkl\")\n",
    "jl.dump(X_test_transformed, \"X_test.pkl\")\n",
    "jl.dump(submit_df, \"submit_df.pkl\")\n",
    "jl.dump(lb, \"lb.pkl\")\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
