{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "\n",
    "# helpers\n",
    "sys.path.append(\"..\")\n",
    "from helpers.loss_functions import *\n",
    "\n",
    "# data\n",
    "train_path = \"../data/train.csv\"\n",
    "test_path = \"../data/test.csv\"\n",
    "\n",
    "# model\n",
    "is_tunning = True\n",
    "device = \"cpu\"\n",
    "goal = \"binary:logistic\"\n",
    "objective_dict = {\"binary:logistic\": {\"metric\": \"MCC\"}}\n",
    "\n",
    "metric = objective_dict[goal][\"metric\"]\n",
    "best_params = {\n",
    "    \"objective\": goal,\n",
    "    \"device\": device,\n",
    "    \"tree_method\": \"exact\",\n",
    "    \"verbosity\": 0,\n",
    "}\n",
    "try:\n",
    "    rs = subprocess.check_output(\"nvidia-smi\")\n",
    "    device = \"cuda\" if rs is not None else \"cpu\"\n",
    "    print(f\"device: {device}\")\n",
    "except (\n",
    "    Exception\n",
    "):  # this command not being found can raise quite a few different errors depending on the configuration\n",
    "    print(\"No Nvidia GPU in system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "print(f\"train size: {train.shape}\")\n",
    "test = pd.read_csv(test_path)\n",
    "print(f\"test size: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"class\"\n",
    "\n",
    "categorical_cols = train.drop(columns=target).select_dtypes(include=\"object\").columns.to_list()\n",
    "for c in categorical_cols:\n",
    "    train[c] = train[c].astype('category')\n",
    "    test[c] = test[c].astype('category')\n",
    "numerical_cols = train.drop(columns=\"id\").select_dtypes(include=\"number\").columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.drop(columns=target),\n",
    "    train[target],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train[target],\n",
    ")\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create the numerical and categorical pipelines\n",
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the full pipeline with the XGBoost model\n",
    "data_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "\n",
    "# Binarize the target labels\n",
    "lb = LabelBinarizer()\n",
    "y_train_binarized = lb.fit_transform(y_train)\n",
    "y_val_binarized = lb.transform(y_val)\n",
    "\n",
    "# prepare data for training\n",
    "dtrain = xgb.DMatrix(X_train_transformed, label=y_train_binarized)\n",
    "dval = xgb.DMatrix(X_val_transformed, label=y_val_binarized)\n",
    "dtest = xgb.DMatrix(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import optuna\n",
    "from datetime import datetime, timezone\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "import warnings\n",
    "from sklearn.metrics import r2_score\n",
    "import xgboost as xgb\n",
    "import joblib as jl\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        **best_params,\n",
    "        **{\n",
    "            # use exact for small dataset.\n",
    "            # defines booster, gblinear for linear functions.\n",
    "            \"booster\": trial.suggest_categorical(\n",
    "                \"booster\", [\"gbtree\", \"gblinear\", \"dart\"]\n",
    "            ),\n",
    "            # L2 regularization weight.\n",
    "            \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "            # L1 regularization weight.\n",
    "            \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
    "            # sampling ratio for training data.\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "            # sampling according to each tree.\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        },\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        # maximum depth of the tree, signifies complexity of the tree.\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
    "        # minimum child weight, larger the term more conservative the tree.\n",
    "        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        # defines how selective algorithm is.\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\n",
    "            \"grow_policy\", [\"depthwise\", \"lossguide\"]\n",
    "        )\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\n",
    "            \"sample_type\", [\"uniform\", \"weighted\"]\n",
    "        )\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\n",
    "            \"normalize_type\", [\"tree\", \"forest\"]\n",
    "        )\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "    evals_result = {}\n",
    "    xgb.train(\n",
    "        params=best_params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=10000,\n",
    "        evals=[(dval, \"eval\")],\n",
    "        feval=mcc_metric,\n",
    "        evals_result=evals_result,\n",
    "        early_stopping_rounds=200,\n",
    "    )\n",
    "    return evals_result[\"eval\"][metric][-1]\n",
    "\n",
    "\n",
    "if is_tunning:\n",
    "    # Create or load a study\n",
    "    today = datetime.now(timezone.utc).strftime(\"%Y_%m_%d\")\n",
    "    curr_timestamp = int(datetime.now(timezone.utc).timestamp())\n",
    "    study_name = f\"study\"\n",
    "    study = optuna.create_study(\n",
    "        study_name=study_name,\n",
    "        storage=f\"sqlite:///{study_name}.db\",\n",
    "        direction=\"maximize\",\n",
    "        load_if_exists=True,\n",
    "    )\n",
    "    study.optimize(objective, n_trials=100, timeout=None, show_progress_bar=True)\n",
    "    # Print best trial\n",
    "    best_trial = study.best_trial\n",
    "    print(\"Best trial:\")\n",
    "    print(f\" {metric}:\", best_trial.value)\n",
    "    print(\"  Params: \")\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "    study_best_params = study.best_params\n",
    "    best_params.update(study_best_params)\n",
    "    jl.dump(best_params, \"best_params.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "import xgboost as xgb\n",
    "from typing import Tuple\n",
    "\n",
    "print(\"Training best model...\")\n",
    "evals_best_result = {}\n",
    "# Create the full pipeline with the XGBoost model\n",
    "model = xgb.train(\n",
    "    params=best_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=10000,\n",
    "    evals=[(dval, \"eval\")],\n",
    "    feval=mcc_metric,\n",
    "    evals_result=evals_best_result,\n",
    "    early_stopping_rounds=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcc = evals_best_result[\"eval\"][metric][-1]\n",
    "print(f\"correlation coefficient: {mcc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, classes = matthews_corrcoef_score(model, dtest, None, lb)\n",
    "\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = test[\"id\"]\n",
    "submit_df[\"class\"] = classes\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
