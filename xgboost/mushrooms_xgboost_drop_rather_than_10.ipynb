{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import gc\n",
    "import optuna\n",
    "from datetime import datetime, timezone\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "import joblib as jl\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from mlflow.models import infer_signature\n",
    "import mlflow\n",
    "import random\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelBinarizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "today = datetime.now(timezone.utc).strftime(\"%Y_%m_%d\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from hyper_params import (\n",
    "    mushroom_tuning_2024_08_06_1722934727_params,\n",
    ")\n",
    "\n",
    "# helpers\n",
    "\n",
    "\n",
    "SEED = 108\n",
    "random.seed(SEED)\n",
    "N_FOLDS = 7\n",
    "# data\n",
    "train_path = \"../../data/mushrooms/train.csv\"\n",
    "test_path = \"../../data/mushrooms/test.csv\"\n",
    "cache_path = \"../../data/mushrooms/cache\"\n",
    "# model\n",
    "is_tunning = True\n",
    "try:\n",
    "    rs = subprocess.check_output(\"nvidia-smi\")\n",
    "    device = \"cuda\" if rs is not None else \"cpu\"\n",
    "except (\n",
    "    Exception\n",
    "):  # this command not being found can raise quite a few different errors depending on the configuration\n",
    "    print(\"No Nvidia GPU in system!\")\n",
    "    device = \"cpu\"\n",
    "goal = \"binary:logistic\"\n",
    "\n",
    "# custom metric\n",
    "objective_dict = {\n",
    "    \"binary:logistic\": {\n",
    "        \"metric\": {\n",
    "            \"is_custom\": False,\n",
    "            \"name\": \"logloss\",\n",
    "            \"fval\": None,\n",
    "        },\n",
    "        \"direction\": \"minimize\",\n",
    "    }\n",
    "}\n",
    "# objective_dict = {\n",
    "#     \"binary:logistic\": {\n",
    "#         \"metric\": {\n",
    "#             \"is_custom\": True,\n",
    "#             \"name\": \"MCC\",\n",
    "#             \"fval\": mcc_metric_v2,\n",
    "#         },\n",
    "#         \"direction\": \"maximize\",\n",
    "#     }\n",
    "# }\n",
    "metric = objective_dict[goal][\"metric\"][\"name\"]\n",
    "is_custom_metric = objective_dict[goal][\"metric\"][\"is_custom\"]\n",
    "fval = objective_dict[goal][\"metric\"][\"fval\"]\n",
    "direction = objective_dict[goal][\"direction\"]\n",
    "\n",
    "best_params = {\n",
    "    \"device\": device,\n",
    "    \"verbosity\": 0,\n",
    "    \"objective\": goal,\n",
    "}\n",
    "best_params.update(mushroom_tuning_2024_08_06_1722934727_params)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(train_path)\n",
    "print(f\"train size: {train.shape}\")\n",
    "X_test = pd.read_csv(test_path)\n",
    "print(f\"test size: {X_test.shape}\")\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = X_test[\"id\"]\n",
    "y_train = train[\"class\"]\n",
    "X_train = train.drop(columns=[\"id\", \"class\"], axis=1)\n",
    "X_test.drop(columns=[\"id\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"class\"\n",
    "\n",
    "categorical_cols = (\n",
    "    train.drop(columns=target).select_dtypes(include=\"object\").columns.to_list()\n",
    ")\n",
    "# for c in categorical_cols:\n",
    "#     train[c] = train[c].astype(\"category\")\n",
    "#     X_test[c] = X_test[c].astype(\"category\")\n",
    "numerical_cols = (\n",
    "    train.drop(columns=\"id\").select_dtypes(include=\"number\").columns.to_list()\n",
    ")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "\n",
    "# get top 10 most frequent names\n",
    "n = 10\n",
    "for c in categorical_cols:\n",
    "    train_mode_values = X_train[c].value_counts()[:n].index.tolist()\n",
    "    X_train.loc[~X_train[c].isin(train_mode_values), c] = \"other\"\n",
    "    test_mode_values = X_test[c].value_counts()[:n].index.tolist()\n",
    "    X_test.loc[~X_test[c].isin(test_mode_values), c] = \"other\"\n",
    "\n",
    "\n",
    "# Create the numerical and categorical pipelines\n",
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"num_imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        # (\"minmax\", MinMaxScaler()),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"cat_imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        # (\"ordinal\", OrdinalEncoder()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine the pipelines into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_pipeline, numerical_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the full pipeline with the XGBoost model\n",
    "data_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "    ]\n",
    ")\n",
    "data_pipeline.set_output(transform=\"polars\")\n",
    "# Preprocess the data\n",
    "X_all = pd.concat([X_train, X_test])\n",
    "data_pipeline.fit(pl.from_pandas(X_all))\n",
    "X_test_transformed = data_pipeline.transform(X_test)\n",
    "X_train_transformed = data_pipeline.transform(X_train)\n",
    "# Binarize the target labels\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "y_train_binarized = lb.fit_transform(y_train)\n",
    "\n",
    "print(f\"Exporting to pickple...\")\n",
    "jl.dump(X_train_transformed, \"X_train.pkl\")\n",
    "jl.dump(y_train_binarized, \"y_train.pkl\")\n",
    "jl.dump(X_test_transformed, \"X_test.pkl\")\n",
    "jl.dump(submit_df, \"submit_df.pkl\")\n",
    "jl.dump(lb, \"lb.pkl\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "clf: xgb.XGBClassifier = xgb.XGBClassifier(\n",
    "    **best_params,\n",
    "    n_estimators=4000,\n",
    "    early_stopping_rounds=50,\n",
    "    enable_categorical=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS)\n",
    "\n",
    "# kf = KFold(n_splits=N_FOLDS)\n",
    "y_preds = []\n",
    "y_trues = []\n",
    "for train_index, test_index in tqdm(skf.split(X_train_transformed, y_train_binarized)):\n",
    "    X_train, X_test = X_train_transformed[train_index], X_train_transformed[test_index]\n",
    "    y_train, y_test = y_train_binarized[train_index], y_train_binarized[test_index]\n",
    "\n",
    "    clf.fit(X=X_train, y=y_train, eval_set=[(X_test, y_test)])\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_preds.append(y_pred)\n",
    "    y_trues.append(y_test)\n",
    "# Concatenate the predictions and true labels\n",
    "y_preds_concat = np.concatenate(y_preds)\n",
    "y_trues_concat = np.concatenate(y_trues)\n",
    "mcc = matthews_corrcoef(y_trues_concat, y_preds_concat)\n",
    "print(f\"Validation mcc score: {mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test_transformed)\n",
    "pred_classes = lb.inverse_transform(y_preds)\n",
    "submit_df[\"class\"] = pred_classes\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
