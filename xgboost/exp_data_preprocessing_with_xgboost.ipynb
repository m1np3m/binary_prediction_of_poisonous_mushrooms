{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import numpy as np\n",
    "import joblib as jl\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    OrdinalEncoder,\n",
    "    LabelBinarizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "SEED = 108\n",
    "random.seed(SEED)\n",
    "train_path = \"/home/manpm/Developers/kaggle/data/mushrooms/train.csv\"\n",
    "test_path = \"/home/manpm/Developers/kaggle/data/mushrooms/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train = pd.read_csv(train_path)\n",
    "print(f\"train size: {train.shape}\")\n",
    "X_test = pd.read_csv(test_path)\n",
    "print(f\"test size: {X_test.shape}\")\n",
    "submit_df = pd.DataFrame()\n",
    "submit_df[\"id\"] = X_test[\"id\"]\n",
    "y_train = train[\"class\"]\n",
    "X_train = train.drop(columns=[\"id\", \"class\"], axis=1)\n",
    "X_test.drop(columns=[\"id\"], inplace=True, axis=1)\n",
    "\n",
    "# prepare columns\n",
    "target = \"class\"\n",
    "\n",
    "categorical_cols = (\n",
    "    train.drop(columns=target).select_dtypes(include=\"object\").columns.to_list()\n",
    ")\n",
    "\n",
    "\n",
    "numerical_cols = (\n",
    "    train.drop(columns=\"id\").select_dtypes(include=\"number\").columns.to_list()\n",
    ")\n",
    "gc.collect()\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "# get top 10 most frequent names\n",
    "n = 15\n",
    "for c in categorical_cols:\n",
    "    train_mode_values = X_train[c].value_counts()[:n].index.tolist()\n",
    "    X_train.loc[~X_train[c].isin(train_mode_values), c] = \"other\"\n",
    "    test_mode_values = X_test[c].value_counts()[:n].index.tolist()\n",
    "    X_test.loc[~X_test[c].isin(test_mode_values), c] = \"other\"\n",
    "    X_train[c] = pd.Series(X_train[c], dtype=\"category\")\n",
    "    X_test[c] = pd.Series(X_test[c], dtype=\"category\")\n",
    "    gc.collect()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    ")\n",
    "# Encode the target variable\n",
    "lb = LabelBinarizer()\n",
    "# Preprocessing for DMatrix\n",
    "lb.fit(np.concatenate([y_train, y_val], axis=0))\n",
    "y_train = lb.transform(y_train)\n",
    "y_val = lb.transform(y_val)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, nthread=-1, enable_categorical=True)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, nthread=-1, enable_categorical=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(\n",
    "    **{\n",
    "        \"device\": \"cuda\",\n",
    "        \"verbosity\": 0,\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"eta\": 0.0696294726051571,\n",
    "        \"max_depth\": 0,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"gamma\": 0.044230646284796976,\n",
    "        \"subsample\": 0.9405269471473167,\n",
    "        \"colsample_bytree\": 0.2999355523666192,\n",
    "        \"lambda\": 0.9746051811186938,\n",
    "        \"alpha\": 4.210861941737071,\n",
    "    },\n",
    "    n_estimators=10000,\n",
    "    early_stopping_rounds=100,\n",
    "    enable_categorical=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X=X_train, y=y_train, eval_set=[(X_val, y_val)])\n",
    "jl.dump(clf, \"../clf_xgboost.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob = clf.predict_proba(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "\n",
    "y_pred = clf.predict_proba(dval)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "mcc = matthews_corrcoef(y_val, y_pred)\n",
    "print(f\"Validation mcc score: {mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib as jl\n",
    "\n",
    "submit_df = jl.load(\"../submit_df.pkl\")\n",
    "X_test_pkl = jl.load(\"../X_test.pkl\")\n",
    "dtest = xgb.DMatrix(X_test, nthread=-1, enable_categorical=True)\n",
    "\n",
    "y_preds = clf.predict(dtest)\n",
    "pred_classes = lb.inverse_transform(y_preds)\n",
    "submit_df[\"class\"] = pred_classes\n",
    "submit_df.to_csv(\"submission_xgboost.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
